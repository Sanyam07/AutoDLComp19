{
  # Codalab submission
  include: {
    packages: {
      apex: [ # This implies to use it when training druing the submission
        apex
        apex-0.1-py3.5.egg-info
        amp_C.cpython-35m-x86_64-linux-gnu.so
        apex_C.cpython-35m-x86_64-linux-gnu.so
        fused_adam_cuda.cpython-35m-x86_64-linux-gnu.so
        fused_layer_norm_cuda.cpython-35m-x86_64-linux-gnu.so
        syncbn.cpython-35m-x86_64-linux-gnu.so
      ]
    },
    pretrained_weights: [ # List the pretrained weight you want packsubmission.py to include
      BnT_Video_input_128.pth.tar
      Averagenet_RGB_Kinetics_128.pth.tar
      resnet18-5c106cde.pth
    ]
  },

  # Automatic mixed precision ops from the apex module
  use_amp: false,
  amp_args: { # See https://nvidia.github.io/apex/amp.html#opt-levels
    opt_level: "O2" # O0 is normal learning and apex does nothing
    keep_batchnorm_fp32: true,
    loss_scale: "dynamic"
  },

  # General
  log_level: 'DEBUG',
  earlystop: 300, # How many seconds shall we ingest
  check_for_shuffling: false,
  benchmark_transformations: false,
  benchmark_time_till_first_prediction: false,


  # CUDNN
  cudnn_benchmark: false,
  cudnn_deterministic: false # negatively affects performance, only use for testing

  # SEEDS
  tf_seed: 42,
  np_random_seed: 42,
  torch_manual_seed: 42,
  torch_cuda_manual_seed_all: 42,


  # Dataset/DataLoader
  dataset_split_ratio: [85, 15],
  dataloader_args: { # Shuffle isn't working so don't drop last
    train: {
      batch_size: 16,
      pin_memory: true, # faster transfer of data to gpu if true
    }
    test: {
      test_initial_batch_size: 200, # Will be automatically adjusted if too big
      pin_memory: true, # faster transfer of data to gpu if true
    }
  },


  # Model and Optimizer selection algorithms
  model_selector: 'kakao_selector',
  model_selector_args: {
    baseline_selector: {
      selection_args: {
        # Philipp: I assume these should depend on the selected model
        # so for now we expose them here to hardcode them
        modality: 'RGB',
        dropout: 0.3, # if we dont want to use it set it to 0
        num_segments: 4, # this could be also set in the trainer
        freeze_portion: 0.2, # freezes a video network's first percent of layers
        optimizer: 'SGD',
        optim_args: {
          lr: 0.001,
          weight_decay: 0.0005,
        }
      },
    },
    test_selector: {
      selection_args: {
        # Philipp: I assume these should depend on the selected model
        # so for now we expose them here to hardcode them
        modality: 'RGB',
        dropout: 0.3, # if we dont want to use it set it to 0
        num_segments: 4, # this could be also set in the trainer
        freeze_portion: 0.2, # freezes a video network's first percent of layers
    	momentum: 0.9,
        optimizer: 'SGD',
        optim_args: {
          lr: 0.001,
          weight_decay: 0.0005,
        }
      },
    },
    kakao_selector: {
      selection_args: {
        # Philipp: I assume these should depend on the selected model
        # so for now we expose them here to hardcode them
        modality: 'RGB',
        dropout: 0.3, # if we dont want to use it set it to 0
        num_segments: 4, # this could be also set in the trainer
        freeze_portion: 0.2, # freezes a video network's first percent of layers
        freeze_portion_image: 0.0, # freezes a video network's first percent of layers
        optimizer: 'SGD',
        max_size: 224, # maximum resolution to resize the input images/frames
        base: 16, # in case the H != W scale them as multiple of 16
        optim_args: {
          lr: 0.001,
          weight_decay: 0.0005,
          lr_image: 0.025,
          weight_decay_image: 0.001,
    	  momentum_image: 0.9,
        }
      },
    },
  },

  transformations_selector: 'baseline_transforms',
  transformations_selector_args: {
    baseline_transforms: {
    },
    test_transforms: {
      use_gpu_resize: false,
    },
  },

  trainer: 'baseline_trainer',
  trainer_args: {  # If the chosen trainer is a class the args
                   # will be passed as init arguments
    baseline_trainer: {
      t_diff: 0.02,
    },
    test_trainer: {
      bn_prod_limit: 128, # limit of batch_size * num_segments
      num_segments_step: 4000,
      t_diff: 0.02,
      dropout_diff: 1e-3,
    },
  },

  tester: 'baseline_tester',
  tester_args: {  # If the chosen trainer is a class the args
                   # will be passed as init arguments
    baseline_tester: {
      never_leave_train_mode: true
    },
  },
}
